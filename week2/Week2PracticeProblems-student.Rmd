---
title: "STA130H1 -- Winter 2018"
subtitle: Week 2 Practice Problems
author: A. Gibbs and N. Taback
output:
  html_document: default
---

# Instructions

## What should I bring to tutorial on January 19?

Your answers to 1. (a) and 2. (b)

## First steps to answering these questions.

- Download this R Notebook directly into RStudio by typing the following code into the RStudio console window.   

```{r,eval=FALSE}
file_url <- "https://raw.githubusercontent.com/ntaback/UofT_STA130/master/week2/Week2PracticeProblems-student.Rmd"
download.file(url = file_url , destfile = "Week2PracticeProblems-student.Rmd")
```

Look for the file "Week2PracticeProblems-student.Rmd" under the Files tab then click on it to open.

- Change the subtitle to "Week 2 Practice Problems Solutions" and change the author to your name and student number.

- Type your answers below each question.  Remember that [R code chunks](http://rmarkdown.rstudio.com/authoring_rcodechunks.html) can be inserted directly into the notebook by choosing Insert R from the Insert menu (see Using [R Markdown for Class Assignments](https://ntaback.github.io/UofT_STA130/Rmarkdownforclassreports.html)). In addition this R Markdown [cheatsheet](http://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf), and [reference](http://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf) are great resources as you get started with R Markdown. 


# Practice Problems

## Question 1

Exercise 4.2 - 4.6 in the textbook uses data that come with `R`.  The dataset is in the `nycflights13` package, which you must first load with the command `library(nycflights13)`.

**Bring your output for this question to tutorial on Friday January 19 (either a hardcopy or on your laptop). **

(a) Answer the questions in Exercises 4.4, 4.5, and 4.6.    

```{r,eval=FALSE}
library(tidyverse)
library(nycflights13)
glimpse(flights) # if you run this command you can see the variables in the data
glimpse(planes)
glimpse(weather)
```


## Question 2

> The Respiratory Virus Detection Surveillance System collects data from select laboratories across Canada on the number of tests performed and the number of tests positive for influenza and other respiratory viruses. Data are reported on a weekly basis year-round to the Centre for Immunization and Respiratory Infectious Diseases (CIRID), Public Health Agency of Canada. These data are also summarized in the weekly FluWatch report. [Visit the website](https://www.canada.ca/en/public-health/services/surveillance/respiratory-virus-detections-canada.html).

(a)  The data for the report, Week 1 ending January 6, 2018 is [here](https://www.canada.ca/en/public-health/services/surveillance/respiratory-virus-detections-canada/2017-2018/respiratory-virus-detections-isolations-week-1-ending-january-6-2018.html) - click on Table 1.  Explain why this data set is not tidy?

**Bring your output for this question to tutorial on Friday January 19 (either a hardcopy or on your laptop). **

(b) For this exercise you will need to install the library `rvest`.  This code will "scrape" the table from the website and load it into an R data frame. Run the following code to download Table 1 directly into the a data frame called `fludat`.    

NB:  You will not be responsible for understanding how this code and the `rvest` library works (i.e., there will not be a test question on this topic). But, if you are intrested in scraping data from the web [see](https://blog.rstudio.com/2014/11/24/rvest-easy-web-scraping-with-r/).


```{r,eval=FALSE}
# Uncomment next line if the rvest package is not installed
# install.packages("rvest") 
library(rvest)

url <- "https://www.canada.ca/en/public-health/services/surveillance/respiratory-virus-detections-canada/2017-2018/respiratory-virus-detections-isolations-week-1-ending-january-6-2018.html"
 
# download and read table into flu_dat 
flu_dat <- url %>% 
  read_html() %>% 
  html_nodes(xpath = '/html/body/main/div[1]/div[2]/details[1]/table') %>% 
  html_table()

# clean up the file
fludat <- flu_dat[[1]]
dat <- as.data.frame(sapply(select(fludat,2:23), as.numeric))
fludat <- cbind(`Reporting Laboratory`=fludat[,1],dat)
```

Answer the following questions:

(i) Create a tidy version of `fludat`.  Explain how you made the data tidy.

(ii) Which provinces and territories have the highest positive rates for Flu A and Flu B.

(iii) The odds of testing positive for, say, Flu A in a province or territory is:

$$\frac{\hat p_{\text province}}{(1-\hat p_{\text province})},$$
where $\hat p_{\text province}$ is the proportion that tested positive for Flu A.  The odds ratio of testing positive for, say Flu A, in Newfoundland versus Ontario is:

$$\frac{\hat p_{\text Newfoundland}/(1-\hat p_{\text Newfoundland})}{\hat p_{\text Ontario}/(1-\hat p_{\text Ontario})} $$

- Calculate the odds ratio for testing positive for Flu A in each province versus Ontario. Interpret odds ratio larger than one, less than one, and equal to one.
- Use the `ggplot` library to plot the odds ratios.  Explain why you selected this type of plot.
- Try the same plot except take the logarithm of the odds ratio. This is called the log odds.  Interpret the log odds.


## Question 3

(a) In this exercise you will create several histograms of math scores in `SAT_2010` data in the `mdsr` library (see page 39, 41 of MDSR) where you specify different lengths of histogram bins using `ggplot()`.

- Create a histogram without specifying the `binwidth` argument.  What do you notice?
- Create histograms where `binwidth` has the values 10, 15, and 20. 

Which histogram is the most accurate representation of the distribution of math scores?


(b)  In this exercise you will recreate the histograms from (b), but will add several arguments to `geom_histogram()`: `aes(y=..density..)`; `alpha`; `fill`; and `colour` (a list of colours is [here](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf) and see [here for alpha, fill, and colour](http://ggplot2.tidyverse.org/reference/aes_colour_fill_alpha.html))) .  The density argument changes the $y$-axis to relative frequency, and `aes(y=..count..)` specifies that frequency should be used on the $y$-axis.  Here is starter code:

```{r,warning=FALSE,message=FALSE,eval=FALSE}
library(mdsr)
library(tidyverse)
SAT_2010 %>% ggplot(aes(x=math)) + geom_histogram(aes(y=..density..),binwidth = 10,fill="darkgrey",colour="black",alpha=.1) 
```

Try different values of `alpha` and colours to create a histogram that's easy to interpret.  Also, try the histogram with frequency and relative frequency on the $y$-axis.  Which is easier to interpret?  

<a href="https://raw.githubusercontent.com/ntaback/UofT_STA130/master/week2/Week2PracticeProblems-student.Rmd"> R Markdown source   <i class="fa fa-github" aria-hidden="true"></i></a> 